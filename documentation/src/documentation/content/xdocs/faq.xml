<?xml version="1.0" encoding="UTF-8"?>

<!DOCTYPE faqs PUBLIC "-//APACHE//DTD FAQ V2.0//EN" "http://forrest.apache.org/dtd/faq-v20.dtd">

<faqs>
  <title>Frequently Asked Questions</title>
  <faqsection id="common">
   <title>Common Grinder Questions</title>
   <faqsection id="general">
    <title>General</title>

    <faq id="name">
      <question>
  So its called "<em>The</em> Grinder" then?
      </question>
      <answer>
  <p>Yes. "<em>The</em> Grinder" is preferred over just plain "Grinder".</p>
      </answer>
    </faq>

    <faq id="g2vsg3">
      <question>
  Should I use The Grinder 2 or The Grinder 3?
      </question>
      <answer>
  <p>The Grinder 3. The Grinder 3 has many <a
  href="site:g3/whats-new">enhancements</a> over The Grinder 2.
  The Grinder 3 is in active development.</p>

  <p>If you continue to use The Grinder 2, be aware that it has
  defects (including <a href="#premature-eof">this one</a> and <a
  href="#extra-line">this one</a>) that will not be fixed.</p>
      </answer>
    </faq>

    <faq id="grinder-vs-loadrunner">
      <question>
  How does The Grinder stack up against a commercial tool like
  Mercury Interactive's LoadRunner&#8482;?
      </question>

      <answer>
    <p>Here is an edited version of <a
    href="mailto:tom.braverman@bea.com">Tom Braverman</a>'s post
    to <a href="site:mail/grinder-use">grinder-use</a>.</p>

  <dl>
        <dt/>
  <dd class="quote"> A few reasons:

    <ul>
      <li>The Grinder is lightweight

        <p>Compared to setting up LoadRunner or some other full
        featured tools, The Grinder is trivial to install and
        get running.</p>
      </li>

      <li>The Grinder is a <em>programmer's load tester</em>

        <p>Too often, programmers defer load testing to some
        other group (e.g., QA) and don't test their own
        components for scalability. The Grinder is designed for
        people who understand the code that they're hitting -
        it's not just a "black box" with a set of associated
        response times.</p>

        <p>Since tests can be coded - and not simply scripted,
        programmers get to test interior tiers of their
        application and not just response time via the user
        interface.</p>
      </li>

      <li>The Grinder is free

        <p>I'm a consulting professional and I have to come up
        with solutions to deadlocks and slow downs. Sometimes I
        only have hours to recreate a problem and then attempt
        to resolve it. I can't count on my client having a given
        load testing tool and many (most?) development teams
        don't have any such tool (they defer this type of
        testing to QA as mentioned above). I can bring The
        Grinder in and set it up and apply load quite
        quickly.</p>
      </li>
    </ul>

    <p>Summarizing: I don't try and persuade my clients that The
    Grinder is a replacement for LoadRunner, etc. I tell them
    that The Grinder is for use by the developers and that
    they'll still want the QA team to generate scalability
    metrics using LoadRunner or some other tool approved for the
    purpose by management.</p>

    <p>Story: One client was attempting to determine scalability
    based on LoadRunner. The LoadRunner team - with no
    understanding at all of the app - was telling them that some
    pages were giving response times of 30 seconds. The project
    manager knew this was patent BS since he could hit the enter
    key on his page and only count to 3 or 4 before the page
    displayed. The client spent many resource days attempting to
    understand LoadRunner numbers. Within a few hours, The
    Grinder was up and running and reporting numbers that
    appeared to track with the user experience. The Grinder
    became the gold standard that the client used to measure
    LoadRunner.</p>
    </dd>
  </dl>

  <p>Its worth adding to this that many companies <em>are</em>
  using The Grinder for production load testing.</p>
      </answer>
    </faq>

    <faq id="subscribe">
      <question>
  How do I subscribe/unsubscribe from The Grinder mailing lists?
      </question>

      <answer>
  <p>You can subscribe and unsubscribe at <a
  href="ext:sourceforge/grinder-mail">Sourceforge</a>. <a
  href="site:support">More details</a>.</p>
      </answer>
    </faq>
  </faqsection>
  <faqsection id="running">
    <title>Running the tests</title>

    <faq id="threads-vs-processes">
      <question>
        How do I control the number of simulated users?
      </question>

      <answer>
  <p>Typically a worker thread is thought of as a client context
  which can simulate a concurrent user. You can control the
  number of worker processes per agent and the number of threads
  per process. You shouldn't need to run more than one agent
  process per machine. The number of simulated users is then</p>

  <source>
number of worker threads x number of worker processes x number test machines
  </source>

  <p>To simulate additional users it is usually better to
  increase the number of worker threads rather than the number
  of processes except where:</p>

  <ul>
    <li>Your JVM threading implementation is particularly
    inefficient. This is not such a problem nowadays. Running
    several hundred threads per process is usually fine.</li>

    <li>The protocol you are using will behave differently when
    distributed across multiple processes. For example, the
    WebLogic Server t3 protocol is optimised so that a single
    TCP/IP connection is used between any two processes.</li>
  </ul>
      </answer>
    </faq>

    <faq id="multiple-scripts">
      <question>
  Can I run different test scripts against the same console?
      </question>

      <answer>
  <p>Yes.</p>

  <p>The console receives reports and updates the graph based on
  test number. Thus it is possible to have different agent
  processes running scripts with different test numbers (e.g.
  one process running tests 1 to 5 and another running tests 6
  to 10)., reporting to the same console.</p>
      </answer>
    </faq>

    <faq id="testrun-period">
      <question>
  How do I run the tests for a specific period of time?
      </question>

      <answer>
  <p>Use the console to control the test. If you want the tests
  to run for an hour and your sample interval is set to 5
  seconds, set the console to collect 720 samples.</p>

  <p>If you're not using the console, see <a
  href="site:getting-started/properties">grinder.duration</a>.</p>
      </answer>
    </faq>

    <faq id="serverside-stats">
      <question>
  Is there any way to record CPU utilisation of the server?
      </question>

      <answer>
  <p>No. The Grinder only measures the response of the test
  server as a black box. Look to other tools such as
  <code>sar</code> and <code>vmstat</code> to measure server CPU
  utilisation.</p>
      </answer>
    </faq>
  </faqsection>

  <faqsection id="statistics">
    <title>Statistics</title>
    <faq id="raw-data">
      <question>
  Where is the raw data stored?
      </question>

      <answer>
  <p>Liam Morley asked:</p>

  <p class="quote">I understand that all the information from
  the workers is sent back to the client, but all I see thus far
  is rough statistical data which seems to have been compiled
  from the raw data. When the data is sent back to the console,
  where is it stored?</p>

  <p>For efficiency, the worker processes only send back
  aggregate information to the console, not the raw data. Each
  worker process sends the console a report every 500ms. The
  report contains information for each test that was invoked
  during the period which includes the number of invocations,
  the total time taken, the number of errors, and any other
  custom statistics.</p>

  <p>Each worker process writes out the raw information to a
  process specific data file. This are the <em>data_...</em>
  files that are stored with the other log files.</p>

  <p>Apart from the raw data, another advantage that these files
  give you that the console doesn't is a record of the testing
  time line. Whilst the console graphs present this information
  graphically, the console only allows you to save snapshots of
  the current statistics.</p>
      </answer>
    </faq>

    <faq id="calculation">
      <question>
  How does the Grinder calculate the mean time and TPS?
      </question>

      <answer>
  <p>Each worker process records the time taken by each thread
  for each test and regularly reports the mean time for each
  test to the console. The console calculates the mean time for
  each test across all worker processes. This is the <em>mean
  time</em>.</p>

  <p>Tests per second (TPS) is calculated by the console. It is
  the sum of the number of tests performed by all worker
  processes within the sampling period, divided by the duration
  of the sampling period. Using longer sampling periods will
  give better averages, but the console display will be updated
  less frequently.</p>
  </answer>
    </faq>

    <faq id="norelation">
      <question>
  What is the relation between mean time and TPS?
      </question>

      <answer>
  <p>In general there is not a linear relationship between the
  test time and the number of tests per second.</p>

  <p>Most time in a typical server-side application is spent
  waiting on I/O. Elapsed time is not the sum the time spent by
  all of the threads. If I have a simple servlet or EJB that
  does the following:</p>

<source>
void doit() { Thread.sleep(1000); // 1 second }
</source>

  <p>Say with this I get 100 TPS and a 1.2 second response time.
  If I now change the code to:</p>

<source>
void doit() { Thread.sleep(10000); // 10 seconds }
</source>

  <p>the system isn't doing any more work and I'd expect to get
  100 TPS and a 10.2 second response time.</p>

  <note>This is only true assuming we have infinite server side
  threads. In practice, the size of a server side thread pool
  has a significant effect on the behaviour of a system. I hope
  that this discussion helps you see that there is no direct
  connection between TPS and test time.</note>
      </answer>
    </faq>
  </faqsection>

  <faqsection id="HTTP">
    <title>HTTP</title>

    <faq id="postsVsGets">
      <question>
  Why do POSTs take longer than GETs?
      </question>

      <answer>
  <p>Dennis Linnell wondered this. This is what he found
  out:</p>

  <dl>
          <dt/>
    <dd class="quote">
      <p>A network protocol trace revealed that the differences
      in POST vs. GET times were attributable to the following:</p>

      <ol>
        <li>The Grinder (HTTPClient) sends a GET request as a
        single TCP protocol data unit (PDU), which requires a
        single acknowledgement (ACK). This is normal and
        expected.</li>

        <li>HTTPClient sends a POST as two PDUs: The first
        includes everything but the Name/Value pairs and
        requires an ACK; the second includes only the Name/Value
        pairs and also requires an ACK. This is a consequence of
        the conservative implementation of HTTP/1.1 pipelining
        in HTTPClient.</li>

        <li>When the first PDU of the POST arrives at the
        Windows XP TCP/IP protocol stack on the server, the
        <em>delayed ACK</em> feature of TCP/IP RFC 1122 kicks
        in. If another request were to arrive, the stack would
        send an ACK; otherwise it waits up to 200 ms. and then
        sends an ACK. Since, in this case, no other request
        arrives, <a href="ext:microsoft/support/delayed-ack">the
        stack delays the ACK</a>. Naturally, I made the changes
        outlined in the Microsoft knowledge base and it solved
        the problem for me. Case closed? Maybe not.</li>

        <li>Still, the question remains, <em>Is the HTTPClient
        behavior reasonable?</em>. I traced Microsoft Internet
        Explorer 6 (latest patch level) and it sends a POST in
        one PDU and thus does not invoke the dreaded <em>delayed
        ACK</em>. On the other hand, Firefox 1.0.4 (oddly)
        requires 3 pairs of PDUs to get the job done. So
        HTTPClient is somewhere in between.</li>

        <li>As HTTPClient's behavior is not in violation of the
        HTTP/1.1 RFC, I have no reason to complain. And, looking
        at the HTTPClient code, I'm certainly not bold enough to
        touch it. Still, it doesn't quite model the behavior of
        the market-leading web browser accurately.</li>
      </ol>
    </dd>
  </dl>
      </answer>

    </faq>
    <faq id="browserVsgrinder">
      <question>
        For a given web page, why does a Grinder script take a much longer time to complete than my browser takes to display the page?
      </question>
      <answer>
        <p>How your web application behaves under non-trivial load and how long it
        takes to display a page are two distinct concerns.</p>
        <p>The Grinder runs through test script elements sequentially while browsers,
        such as MS Internet Explorer, can request several elements at the same time
        using parallel threads. The number of parallel threads depends on the browser type,
        MS Internet Explorer typically uses 3. Therefore the browser should complete requesting
        the complete list of elements from a web page before the Grinder.</p>
        <p>If you are concerned over page download times rather than application behaviour under
        load then <a href="mailto:pbooth@marketaxess.com">Peter Booth</a> writes:</p>
  <dl>
          <dt/>
    <dd class="quote">
To understand how a typical browser will download and display *your* page you should use a tool like IBM's <a href="http://www.alphaworks.ibm.com/tech/pagedetailer">Page Detailer</a>
which intercepts and instruments all browser activity and visualises this in an easy to interpret fashion.
 It can highlight tuning opportunities like coalescing JavaScript, reducing GIF count, that are more in the
page design than dynamic application design arena.
    </dd>
  </dl>
        <p>From the IBM Page Detailer Web Site</p>
  <dl>
          <dt/>
    <dd class="quote">
IBM Page Detailer places a probe in the Windows Socket Stack to capture data
about timing, size, and data flow, and then it presents the collected data in both
graphical and tabular views, clearly showing how the page was delivered to the browser.
    </dd>
  </dl>

        <p>Tools like IBM Page Detailer are a useful addition to your arsenal
        when looking at the complete picture.

        The <a href="https://addons.mozilla.org/firefox/966/">tamperdata</a>
        add-on for Firefox is also worth a look. </p>
      </answer>
    </faq>
  </faqsection>

  <faqsection id="problems">
    <title>Problems</title>

    <faq id="negative-times">
      <question>
  I've seen The Grinder report negative test times?!
      </question>

      <answer>
  <p>Are you running Linux kernel 2.2.18? Mikael Suokas
  reports:</p>

  <dl>
          <dt/>
    <dd class="quote">
      <p>In some load situations, on some hardware, older Linux
      kernels can generate system times that jump backwards. I
      have experienced this problem on one machine (Intel
      Pentium/150, 128M RAM, Adaptec AHA-2940, SCSI disks)
      running the stock Red Hat Linux 7.0 kernel (2.2.16).</p>

      <p>The Grinder occasionally reported negative response
      times in the -900 to -700 ms range whenever the load
      became high. Interestingly, the same OS + kernel version
      on several other machines never showed these negative
      response times. The problem was not Grinder or Java
      specific: a C program polling gettimeofday() also showed
      system time jumping backwards.</p>

      <p>Upgrading to kernel 2.2.19 fixed this issue for me.
      Since the release notes for Linux 2.2.18 mention time
      keeping locking fixes, I don't think that was a
      coincidence.</p>

      <p>Of course, you should upgrade any 2.2.x kernel to
      2.2.19 anyway, because because of the many security
      fixes.</p>
    </dd>
  </dl>
      </answer>
    </faq>

    <faq id="windows-address-in-use">
      <question>
  What can I do about <em>address in use</em> exceptions on
  Microsoft Windows machines?
      </question>

      <answer>
  <p>Answer courtesy of Venkat:</p>

  <dl>
          <dt/>
    <dd class="quote">
      <p>Recently, there have been a couple posts from people
      facing the <em>address in use</em> exception when running
      The Grinder. I also faced the same issue and here is what
      I found and how I resolved it.</p>

      <p>Windows OS TCP-IP system has a parameter that controls
      the maximum port number used when an application requests
      any available user port from the system. By default,
      ephemeral (that is, short-lived) ports are allocated
      between the values of 1024 and 5000 inclusive. During a
      Grinder test, if we exceed this limit, we get the
      <em>address in use</em> exception. To make it more
      complicated, there is another parameter that says once the
      application closes a TCP connection, how long the OS will
      wait before reclaiming the port for the connection. The
      default value for this is 4 minutes.</p>

      <p>Due to the above, often the default Windows
      configuration isn't sufficient to run load tests. To change
      this, modify the following Registry values under the key
      <code>HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\Tcpip\Parameters</code>:</p>

<source>
MaxUserPort       = dword:00004e20 (20,000 decimal)
TcpTimedWaitDelay = dword:0000001e (30 decimal)
</source>

      <p>The above was sufficient for my testing. Adjust the
      <code>MaxUserPort</code> to a larger number if you still
      run into the exception. Of course, the OS needs to be
      rebooted once the setting is changed. MS documentation
      says the <code>MaxUserPort</code> setting is available
      since Windows NT 3.51 Service Pack 5. I am not sure which
      version introduced the <code>TcpTimedWaitDelayed</code>
      setting. You can confirm whether your OS version supports
      this by looking into the Registry location above.</p>
    </dd>
  </dl>
      </answer>
    </faq>

    <faq id="linux-address-in-use">
      <question>
  What can I do about <em>address in use</em> exceptions on
  Linux machines?
      </question>

      <answer>
  <p>Prabhat Jha writes:</p>

  <dl>
    <dt/>
    <dd class="quote">
      <ol>
      <li>Increase the ephemeral port range:
<source>
echo "32768 65535" > proc/sys/net/ipv4/ip_local_port_range
</source>
	  </li>

	  <li>Enable Port Recycling
<source>
echo "1" > /proc/sys/net/ipv4/tcp_tw_recycle
</source>
	  </li>

	  <li>Reduce the timeout (default is 60 seconds)
<source>
echo "10" >  /proc/sys/net/ipv4/tcp_fin_timeout
</source>
	  </li>
	  </ol>
    </dd>
  </dl>
      </answer>
    </faq>


    <faq>
      <question>
    How do I specify the ephemeral port range?
      </question>
      <answer>
      <p>When a client connects to a TCP server, the client side port uses
      a temporary <em>ephemeral</em> port.
      Occasionally users want to set the ephemeral ports that are
      used for:</p>
      <ul>
      <li>Connections from the agent and worker processes to the console.</li>
      <li>Connections created by the TCPProxy.</li>
      <li>Connections created by the HTTP Plugin.</li>
      </ul>

      <p>The Grinder does not specify the ephemeral port numbers, and
      instead uses values assigned by the operating system's TCP/IP
      stack. If you wish to control the ephemeral port numbers, please
      see <a href="site:ncftp/ephemeral-ports">NCFTP</a> for a good
      HOWTO.</p>.

      </answer>
     </faq>

    <faq id="ten-cps">
      <question>
        Why can't I create more than ten connections per second on Windows XP?
      </question>
      <answer>
      <p>
        If you're using Windows XP SP2,
        <a href="http://www.speedguide.net/read_articles.php?id=1497">this
        article</a> may provide the answer.
      </p>

      </answer>
     </faq>

    <faq id="timing">
      <question>What are the limits to accurate timing?</question>

      <answer>

    <p>The Grinder records test times for each successful test. By
    default, this is done by a section of code that looks like:</p>

  <source>
context.startTimer(); // Critical section starts

try {
    // do test
}
finally {
    context.stopTimer();  // Critical section ends
}
</source>

    <p>This is repeated for each test.</p>

    <p>If there are many threads within the worker process, (and the
    sleep time is small or the test takes a long time or the test
    performs I/O), it is <em>highly</em> likely that the JVM will swap
    the thread out in the critical section causing an erroneously large
    test time to be reported.</p>

    <p>Similarly, if the load injector machine that you are running The Grinder
    on is also running other active processes (such as other worker
    processes), it is <em>highly</em> likely that the operating system will swap
    the process out in the critical section, again causing an erroneously
    large test time to be reported. If The Grinder is co-hosted with the
    target server, and the plug-in uses a synchronous protocol, (e.g.
    the HTTP plug-in), such swapping is a <em>certainty</em>.</p>

    <p>Further, as the CPU utilisation rises, the contention on the
    critical section rises non-linearly and in a way that is difficult
    to quantify. The recorded time becomes more a measure of how efficiently
    the OS and JVM can swap between multiple threads and less a measure of
    server performance.</p>

    <p><em>This is a generic problem with all test harnesses and is not
    limited to The Grinder or Java</em>. Within the scope of a single
    machine there is little that can be done about this whilst
    realistically using multiple threads and processes.</p>

    <strong>Fiddling with Thread scheduling - a partial fix</strong>

    <p>From The Grinder 2.6.1, the call to <code>startTimer</code>
    makes a <code>Thread.yield()</code> call before recording the
    start time which means that a thread is more likely to be swapped
    out/in just before the critical sections. It dramatically reduced
    the response times I measured (e.g. 30 ms to 3 ms). I consider
    this only an approximate fix to the problem - it does not prevent
    the OS from swapping the process out.</p>

    <p>The recorded response time should always be considered an upper
    bound on the actual response time. Doing the <code>yield()</code>
    makes that bound more accurate.</p>

    <p>An argument against doing this is that it slightly alters the
    statistical distribution of the client invocations. I'd counter
    that without the <code>yield()</code> the distribution is not
    even; its down to the OS and JVM scheduling so threads/processes
    are far likely to be swapped at some points (e.g. waiting on I/O)
    than others. Because of this I decided there is little point in
    making the <code>yield()</code> optional.</p>

    <strong>The <em>Timer Client</em> model - a solution?</strong>

    <p>One solution to this problem is to dedicate a single machine to
    the measuring of response times. I call this the "timer client"
    model.</p>

    <p>As of The Grinder 2.6.1 you can set a property (<a
    href="site:g2/getting-started/properties">grinder.recordTime</a> for
    The Grinder 2, renamed to
    <a href="site:g3/getting-started/properties">grinder.reportTimesToConsole</a>
    for The Grinder 3) to be
    <code>false</code> which will cause the worker processes that use
    that <code>grinder.properties</code> file not report the test
    times to the console. You should run all but one
    of your worker processes with this property set to
    <code>false</code>. These are the <em>load clients</em>.</p>

    <p>You should copy the grinder.properties file to a dedicated
    <em>timer client</em> machine, change the
    <code>grinder.recordTime</code>/<code>grinder.reportTimesToConsole</code>
    property to be <code>true</code>, and set <a
    href="site:g2/getting-started/properties">grinder.processes</a> and <a
    href="site:g2/getting-started/properties">grinder.threads</a> to <code>1</code>.
    The single worker process will run on the timing client, record
    all timing information and (optionally) report it to the console.
    The less other stuff you run on the timing client, the better.</p>

    <p>The disadvantage of this method is that the statistical sample
    of the test times is much smaller.</p>

    <strong>An update after some experimentation</strong>

    <p>Testing has shown that the difference the timer client model
    makes is only measurable when those clients are co-hosted with the
    server. When you have separate server and client machines its
    better to not use the timer client model because it decreases the
    sample size of test times.</p>

    <p>I recommend trying both models. If you discover something
    interesting, please report it to <a
    href="ext:mail/grinder-use">grinder-use</a>.</p>

    </answer>
   </faq>

   </faqsection>

  </faqsection>

  <faqsection id="g2">
    <title>The Grinder 2</title>
    <faqsection id="g2-general">
    <title>General</title>
    <faq id="multicast">
      <question>
  What do I need to do to set up multicast?
      </question>

      <answer>
  <p>You must set up multicast if you want to use the console
  with The Grinder 2. It is used to send signals from the
  Console to the Grinder processes (start, stop). Multicast is
  no longer necessary for The Grinder 3.</p>

  <p>Multicast addresses lie in the range <code>224.0.0.0</code>
  to <code>239.255.255.255</code>. Ports lie in the range
  <code>0</code> to <code>65535</code>. You should ensure that
  the address and ports you chose does not clash with other
  applications running on your LAN. The example files uses the
  address <code>228.1.1.1:1234</code>:</p>

<source>
grinder.receiveConsoleSignals=true
grinder.grinderAddress=228.1.1.1
grinder.grinderPort=1234
</source>

  <p>For most modern TCP stacks, e.g Windows 95/98/NT, Linux,
  multicast works out of the box.</p>

  <p>Under Linux, you may also need to set up the routing table.
  Try:</p>

<source>
route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0
</source>

  <p>Some Windows VPN clients (e.g Bay Networks Extranet)
  interfere with multicast. You may need to disable them.</p>
      </answer>
    </faq>

    <faq id="multicast-w2k">
      <question>
  What do I need to do to set up multicast under Windows 2000?
      </question>

      <answer>
  <p>With a stand alone Windows 2000 machine, you might
  experience similar grief to myself. I found that I could only
  get multicast to work if my LAN NIC had a carrier and the MS
  loop-back adapter is not installed (or disabled). The
  following links contain experiences that tally with mine:</p>

  <ul>
    <li><a
    href="http://web.archive.org/web/20030802192353/www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0021.html">
    http://www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0021.html</a></li>

    <li><a
    href="http://web.archive.org/web/20030802192353/www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0023.html">
    http://www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0023.html</a></li>

    <li><a
    href="http://web.archive.org/web/20030802192353/www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0025.html">
    http://www.web3d.org/WorkingGroups/vrtp/dis-java-vrml/hypermail/2001/0025.html</a></li>
  </ul>

  <p>The last of these says:</p>

  <p class="quote">I have been looking for a solution for this
  problem a long time without success :-( I found several dummy
  loop-back IP stacks but none that supports multicast. The
  solution I have been using is to bring along a tiny hub and
  connect my laptop to that hub when doing demos. Windows is a
  bit stupid in the way that it only checks if it has a carrier.
  </p>

  <p>I now use a slightly cheaper/lighter solution; namely I
  have cropped a network cable short and twisted my own physical
  loop-back adapter. Needless to say, if anyone figures out how
  to get multicast working with a stand alone W2K machine, I'm
  more than interested.</p>

  <note>Multicast is no longer required by The Grinder 3.</note>
      </answer>
    </faq>

    <faq id="premature-eof">
      <question>
  Why do I get <code>HTTPClient.RetryException: Premature EOF
  encountered</code> errors when I increase HTTP load?
      </question>

      <answer>
  <p>This is a known issue with The Grinder 2 that is fixed in
  The Grinder 3.0b14. I have no plans to backport the fix to The
  Grinder 2, but see <a
  href="http://article.gmane.org/gmane.comp.java.grinder.user/893/match=premature+eof">this
  e-mail</a> for details of how to do this yourself.</p>
      </answer>
    </faq>

  </faqsection>
  <faqsection id="g2-scripts">
  <title>Scripts</title>
    <faq id="string-beans">
      <question>
  How do I simulate different users with The Grinder 2?
      </question>

      <answer>
  <p>You probably want to use a <a
  href="site:g2/plugins/http-plugin/string-bean">String Bean</a>.</p>
      </answer>
    </faq>

    <faq id="post-and-string-beans">
      <question>
  How do I generate POST data with a String Bean?
      </question>

      <answer>
  <p>Sean Kroah writes:</p>

  <dl>
    <dt/>
    <dd class="quote">
      <p><code>grinder.test0.parameter.post=&lt;getPostData&gt;</code>
      doesn't work.</p>

      <p>I didn't really see this in the docs anywhere so if
      anyone is interested. I needed dynamic post data and the
      HTTP plugin post parameter only took a file name. The key
      was that the file can optionally contain a reference to a
      <a href="site:g2/plugins/http-plugin/string-bean">String Bean</a>
      method. I tried it on a fluke and it worked.</p>

<source>
grinder.test0.parameter.url=&lt;getLoginUrl&gt;
grinder.test0.parameter.post=getPostData.dat
</source>
      <p><code>getPostData.dat</code> has one line in it:</p>

<source>
&lt;getPostData&gt;
</source>

      <p>This tells The Grinder to call my String Bean method
      which returns my dynamic POST content based on the test
      description. I'm pretty pleased with that.</p>
    </dd>
  </dl>
      </answer>
    </faq>
    <faq id="extra-line">
      <question>
  Why do my POSTs have an extra new line?
      </question>

      <answer>
  <p>An anonymous user reports:</p>
  <dl>
    <dt/>
    <dd class="quote">
      <p>The Grinder 2 appends a new line character to the end
      of file which contains post information for a test. This
      appears to happen only under Windows.</p>
    </dd>
  </dl>

  <p>This is a known issue with The Grinder 2 that is fixed in
  The Grinder 3.0. I have no plans to backport the fix to The
  Grinder 2, but see the <a
  href="site:sourceforge/extra-line">bug report</a> for how to
  do this yourself.</p>
      </answer>
    </faq>
  </faqsection>
  </faqsection>

  <faqsection id="g3">
    <title>The Grinder 3</title>
  <faqsection id="g3-general">
  <title>General</title>
    <faq id="startup-time">
      <question>
  Why does The Grinder take a while to start up?
      </question>
      <answer>
  <p>The Grinder 3 worker process start up time is marginally
  slower than The Grinder 2. However, it is much slower when you
  add new Java libraries to your <code>CLASSPATH</code>.</p>

  <p>At start up, the Jython engine processes all new Java
  libraries it finds. When it does this you'll see output
  similar to the following in the window you used to start The
  Grinder:</p>

<source>
*sys-package-mgr*: processing new jar, 'E:\src\grinder3\lib\jakarta-oro-2.0.6.jar'
*sys-package-mgr*: processing new jar, 'E:\src\grinder3\lib\jython.jar'
</source>

  <p>Jython caches the result of this processing, so subsequent
  start up times are much reduced. You can control the location
  of the cache directory, see the information on <a
  href="site:g3/scripts/scripts-intro/jython-installation">Jython
  installation</a>.</p>

      </answer>
    </faq>

    <faq id="junit">
      <question>
  What happened to the JUnit plugin?
      </question>

      <answer>
  <p>The Grinder 2 had a JUnit plugin which allowed JUnit test
  cases to be called. There is no JUnit plugin in The Grinder 3
  but you can call arbitrary Java code so you should be able to
  invoke your JUnit test cases directly.</p>

  <p>If you have a lot of JUnit test cases, it would be
  appropriate to wrap up the steps necessary to invoke a test
  case in a Jython library. Contributions to the <a
  href="site:script-gallery">script gallery</a> are welcome.</p>

  <p>See also <a
  href='http://sourceforge.net/mailarchive/forum.php?thread_id=1687434&amp;forum_id=2650'>
  this article</a> on <em>grinder-use</em>.</p>

      </answer>
    </faq>
    <faq id="grinder-dnsdelay">
      <question>
       The Grinder pauses before either threads start sending data, or the TCPProxy carries out a request, when interacting with webservers. Why is this?
      </question>
      <answer>
      <p><a href="mailto:karol.muszynski@hp.com">Karol
       Muszynski</a> writes:</p>

      <dl>
           <dt/>
      <dd class="quote">
      <p>Solution:<br></br>
      We found that it was a problem with DNS configuration. Solution was to add the web
      servers host names and ip addresses to the windows hosts file.</p>

      <p>Verification:<br></br>
      Simply on the command line write "nslookup", then hit enter, and on the following line type your web server "hostname" and hit enter.
      If this takes a long time to get an ip address, it can mean that this is your problem.</p>
      </dd>
      </dl>

      <p>Common locations for hosts files:</p>
      <p><strong>Windows:</strong> "C:\winnt\system32\drivers\etc\hosts"<br></br>
      <strong>Unix:</strong> "/etc/hosts"
      </p>
      </answer>
    </faq>
    <faq id="grinder-debug">
      <question>
      How do I debug worker processes?
      </question>
      <answer>
      <p>Worker processes are separate child processes of agent processes, so
      they are sometimes a bit fiddly to debug. It is possible to run an agent
      and its workers in a single process. To do this, please start the agent
      with:</p>

<source>
    java -Dgrinder.debug.singleprocess=true net.grinder.Grinder
</source>

      <p>This puts the worker and agent code in a single process, making it
       easier to take a thread dump of the worker code.</p>

      <p>Use the minimum number of threads that cause the problem. When the
      hang is observed, take a <a href="#thread-dumps">thread dump</a> and post
      the output to the <a href="mailto:grinder-use@lists.sourceforge.net">grinder-use</a> mail list.</p>
      </answer>
    </faq>
    <faq id="thread-dumps">
      <question>
      How do I take a thread dump?
      </question>
      <answer>
      <p>A thread dump is a diagnostic report of the state of a Java process. If
      you report an unresponsive grinder process to one of the mailing lists, you
      most likely will be asked to take a thread dump. This answer explains how
      to do that.
      </p>

      <p>First identify the relevant <a href="site:g3/getting-started/getting-started-intro/processes">process</a>,
      and start it from a command line terminal. The output will go to the
      command line, so either set the terminal up so that it has plenty of lines
      of scroll-back or redirect the output of the process to a file. For
      example, you might start an agent process with:
      </p>
      <source>
C:\> java net.grinder.Grinder > output.txt
</source>

      <p>If you are using a UNIX-like operating system, taking the thread dump
      is simple. Just use <code>ps</code> to identify the process id, then issue
      a <code>kill -3 &lt;pid&gt;</code> to send the process a
      <code>SIGQUIT</code> signal. You will find the thread dump in the
      terminal window (or the file to which you redirected output).</p>

      <p>On Windows, use one of the following:</p>
      <ul>
        <li>If it is an <em>agent</em> or <em>console</em> process you are
        interested in (not a <em>worker</em> process), type <code>Ctrl-Break</code>
        in the command line terminal.</li>

        <li>If it is a worker process, things are a little more involved. This is
      because worker processes are children of agent processes, and Java does
      not pass on <code>Ctrl-Break</code> signals to child processes.
      You can work around this problem by running the
      <a href="#grinder-debug">workers and
      the agent in the same process</a>, then using <code>Ctrl-Break</code>
      as above.
        </li>
      </ul>

      <p>Alternatively, you can run a recent version of the Sun JVM (J2SE 5 for
      Linux or Solaris, J2SE 6 for Windows) and use the <code>jstack</code>
      command line. The alternative to <code>jstack</code> for the BEA
      JRockit JVM is the powerful <code>jrcmd</code> command.</p>

      </answer>
    </faq>

    <faq id="cachedir">
      <question>
      Should I be concerned about the "can't create package cache dir" message?
      </question>
      <answer>
      <p>At start up, the agent may log a message about not being able to create
      a package cache directory:</p>
      <source>
2/14/08 2:20:00 PM (agent): worker deep-0 started *sys-package-mgr*: can't create package cache dir 'D:\grinder-3.0.1\lib\jython.jar\cachedir\packages'
</source>

	  <p>This is due to a <a href="ext:sourceforge/jython/cachedir-bug">
	  Jython 2.2.1 bug</a>.</p>

	  <p>You can ignore the warning if you don't rely on Jython <a href="ext:jython-wiki/package-scanning">package scanning</a>
(this is likely).</p>

	  <p>Alternatively, you can specify a cache directory by adding the following
	  to grinder.properties (adjusting <code>/tmp</code> accordingly):</p>
	  <source>
grinder.jvm.arguments: -Dpython.cachedir=/tmp
</source>
      </answer>
    </faq>
  </faqsection>
  <faqsection id="g3-scripts">
    <title>Scripts</title>

    <faq id="http-recording">
      <question>How do I record an HTTP script?</question>

      <answer>
      <p>Using the Grinder 3 it is possible to automatically generate a script
      of your HTTP journey. To do this you need to make use of the TCPProxy and its
      associated HTTP TCPProxy filters. The recommended filter to use is "-http" as the
      other filters are now deprecated. See this <a href="site:g3/getting-started/tcpproxy/HTTPPluginTCPProxyFilter">link</a>
      for how to use the TCPProxy and the recommended filter.</p>
      </answer>
    </faq>

    <faq id="jython-libraries">
      <question>How do I use standard Python
      modules in my scripts?</question>

      <answer>
  <p>The Python standard library contains a number of very
  useful modules. For example the regular expression module
  <code>re</code>, the <code>threading</code> module, and the
  <code>random</code> module. To use these modules you must <a
  href="site:g3/scripts/scripts-intro/jython-installation">install
  Jython</a>.</p>
      </answer>
    </faq>

    <faq id="simulating-users">
      <question>
  How do I simulate different users with The Grinder 3?
      </question>

      <answer>
  <p><a
  href="mailto:calum.fitzgerald@environment-agency.gov.uk">Calum
  Fitzgerald</a> writes:</p>

  <dl>
          <dt/>
    <dd class="quote">
      <p>This is a method we use to generate random users for
      tests on web applications.</p>

      <p>We store the usernames and
      passwords in a text file (eg.users.txt) with the format:
      <code>user,password</code></p>

      <p>We then read in the file and grab the components. The
      reason for using a file to store the usernames is that if
      you are using hundreds or throusands of usernames then
      Jython/Java has a limitation with arrays over 64KB.</p>

      <source>
#
# testRandomise.py
#
import random
import string

class TestRandomise:
  def __init__(self, filename):
    self._users = []
    infile = open(filename, "r")

    for line in infile.readlines():
      self._users.append(string.split((line),','))
    infile.close()

  def getUserInfo(self):
    "Pick a random (user, password) from the list."
    return random.choice(self._users)


#
# Test script. Originally recorded by the TCPProxy.
#
from testRandomise import TestRandomise
tre = TestRandomise("users.txt")

class TestRunner:
    def __call__(self):
        # Get user for this run.
        (user, passwd) = tre.getUserInfo()

  # ...

  # Use the user details to log in.

        tests[2002].POST('https://host:443/securityservlet',
          ( NVPair('functionname', 'Login'),
            NVPair('pagename', 'Login'),
            NVPair('ms_emailAddress', user),
            NVPair('ms_password', passwd), ))
      </source>
    </dd>
  </dl>
      </answer>
    </faq>

    <faq id="parse-response">
      <question>
  Is there a way to make my requests depend on previous
  responses?
      </question>

      <answer>
  <p><a href="mailto:carlos.franco@xeridia.com">Carlos
  Franco</a> asks:</p>

  <p class="quote">Is there a way (with Grinder 3) to make that
  my requests depends on the response?</p>

  <p>Absolutely. This is one of the compelling reasons to use
  The Grinder 3 over The Grinder 2.</p>

  <p class="quote">I will make an example. Supose that when I
  make a request the server gives me one list of, for example,
  cars, and I want to edit the information of one, but I don't
  know its ID, so I have to look into the response and look for
  it. Can I do that?</p>

  <p>I'm assuming HTTP and that the cars come back in a table
  such as</p>

<source>
&lt;td&gt;Jaguar&lt;/td&gt;&lt;td&gt;1234&lt;/td&gt;
&lt;td&gt;Bentley&lt;/td&gt;&lt;td&gt;0012&lt;/td&gt;
&lt;td&gt;Rolls Royce&lt;/td&gt;&lt;td&gt;8323&lt;/td&gt;
&lt;td&gt;Rover&lt;/td&gt;&lt;td&gt;9876&lt;/td&gt;
</source>

  <p>You can get the text of the HTTP response body with
  something like:</p>

<source>
response = myrequest.GET(&quot;/carindex.html&quot;)
text = response.text
</source>

  <p>See the <a href="g3/script-javadoc/index.html">script
  API</a> for other things you can do with the
  <code>HTTPResponse</code> object.</p>

  <p>Now you have the choice of using Java or Python to extract
  the appropriate ID. Lets do it in Python. Rather than write
  low level string parsing, we'll use a regular expression for
  capturing interesting information. To use the standard
  <code>re</code> module, you should install Jython as described
  in <a href="#jython-libraries">this FAQ</a>.</p>

  <p>Regular expressions are faster if compiled, so we'll do
  this up front:</p>

<source>
# Add to top of script
import re
expression = re.compile(r&quot;&lt;td&gt;([\w\s]*)&lt;/td&gt;\s*&lt;td&gt;(\d*)&lt;/td&gt;&quot;)
</source>

  <p>For eyes unused to magic of regular expressions, this one
  matches pairs of table cells, the first cell containing
  alphanumerics and white space, the second containing a number.
  <code>\w</code> matches an alphanumeric ("word") character,
  <code>\s</code> matches a white space character,
  <code>()</code> captures its contents in a group.</p>

  <p>We can then use the regular expression to parse the
  response:</p>

<source>
response = myrequest.GET(&quot;/carindex.html&quot;)

for car, id in expression.findall(response.text):
    print car, id
</source>

  <p>Of course you want to use this to select an ID and use it
  in a subsequent page. Lets pick a random one and use it for a
  new request:</p>

<source>
response = myrequest.GET(&quot;/carindex.html&quot;)

# Import random for this to work.
car,id = random.choice(expression.findall(response.text))

request = myrequest.GET(&quot;/viewcar?id=%d&quot; % id)
</source>
      </answer>
    </faq>

    <faq id="http-caching">
      <question>How do I replay a scenario, caching
      image files but not text files?</question>

      <answer>
  <p>The Grinder itself does not cache files. It merely
  simulates browser behaviour. The
  <code>Not-Modified-Since</code> headers are recorded by the
  TCPProxy filter, so what you record with the TCPProxy is the
  caching behaviour of the browser you are using.</p>

  <p>If this is not what you want you could add a function to
  your test script which takes an HTTPRequest, decides whether
  it should be considered as "cached" or not, and adds a
  <code>Not-Modified-Since</code> header as appropriate.</p>
      </answer>
    </faq>

    <faq id="distribution-directory">
      <question>When using the script distribution feature, how can my scripts refer to other distributed files?</question>

      <answer>
  <p>The directory of the distributed script is prepended to the
  Jython system path. You can do something like:</p>
<source>
  import sys
  f = open("%s/myresources.properties" % sys.path[0])
  # ...
</source>
      </answer>
    </faq>

    <faq id="re-problems">
      <question>Why does the Jython <code>re</code> module raise a
      <code>ValueError</code> when I compile a regular expression?
      </question>

      <answer>
      <p>
      Each thread that you use to compile regular expressions must import the
      <code>re</code> module. If you fail to do this you'll get a
      <code>ValueError</code> like:</p>

      <source>
ValueError: ('unsupported operand type', 'in')
  File "D:\opt\jython\jython-2.1\Lib\sre_compile.py", line 141, in _compile
  File "D:\opt\jython\jython-2.1\Lib\sre_compile.py", line 61, in _compile
  File "D:\opt\jython\jython-2.1\Lib\sre_compile.py", line 352, in _code
  File "D:\opt\jython\jython-2.1\Lib\sre_compile.py", line 368, in compile
  File "D:\opt\jython\jython-2.1\Lib\sre.py", line 134, in _compile
  File "D:\opt\jython\jython-2.1\Lib\sre.py", line 90, in compile
  File "helloworld.py", line 24, in matchAll
  File "helloworld.py", line 39, in __call__
      </source>

      <p>The best (most efficient) way to use regular
      expressions is to compile them in the main part of your script. For
      example:
      </p>

      <source>
import re

# Compile once in initialisation thread
p = re.compile('a.b', re.IGNORECASE)

class TestRunner:
  def __call__(self):
    # use p
      </source>

      <p>Occasionally, the regular expression must be dynamically generated
      by a worker thread, so this technique doesn't work. In this case, you can
      import <code>re</code> in every worker thread:</p>

      <source>
class TestRunner:
  def __init__(self):
    import re

  def __call__(self):
    # __call__ is executed by worker threads
    p = re.compile('a.b', re.IGNORECASE)
    # use p
      </source>

      <p>Or equivalently:</p>
      <source>
from net.grinder.script.Grinder import grinder

def getRE()
  import re
  return re.compile('a.b', re.IGNORECASE)

class TestRunner:
  def __call__(self):
    # __call__ is executed by worker threads
    p = getRE()
    # use p
      </source>
      </answer>
    </faq>
    <faq id="jython-indentation">
      <question>
      Why do I get syntax errors when editing my Jython scripts, even when the code looks correct?
      </question>
      <answer>
      <p>Python and Jython use indentation to delimit blocks. You need to indent your script consistently.</p>
      <p>Check out these links for more information:</p>
      <p><a href="http://diveintopython.org/getting_to_know_python/indenting_code.html">http://diveintopython.org/getting_to_know_python/indenting_code.html</a><br></br>
       <a href="http://www.python.org/doc/current/ref/indentation.html">http://www.python.org/doc/current/ref/indentation.html</a></p>
      </answer>
    </faq>
    <faq id="set-script">
      <question>
      Whenever I try to run scripts I get "the script file 'grinder.py' does not exist or is not readable"?
      </question>
      <answer>
      <p>You need to define which script should be used. If you do not define it the default script name is "grinder.py".</p>
      <p>If your script is not called "grinder.py", either add a line to grinder.properties that specifies its name, e.g.:</p>

<source>
  grinder.script: http.py
</source>

      <p>or specify it on the command line, e.g.:</p>

<source>
  java -Dgrinder.script=http.py net.grinder.Grinder
</source>

      <p>or set it in the console. Go to the script tab, navigate to the location of your script. Select it and then click
      on the "Set script to run" button.</p>
      <p>Finally, it could simply be that the script file is unreadable. Check the file permissions of the script and/or
      attempt to open it in an editor to check if its readable.</p>

      </answer>
    </faq>

    <faq>
    <question>
    What does "java.lang.ClassFormatError: Invalid method Code length" mean?
    </question>
    <answer>
	<p>The short answer is that a function in your script is too long and is
tripping over a Java limitation on the length of a method inherited by
Jython. Java methods are limited to 65535 characters or less.</p>

	<p>You'll need to break the script up into smaller pieces. E.g. if you
	have a script that looks like</p>
	<source>
#...
class TestRunner:
  def __call__(self):
  	# Lots of code - more than 65535 characters
</source>
	<p>you might break it up into smaller methods (functions belonging to
	<code>TestRunner</code>) as follows:</p>
	<source>
#...
class TestRunner:
  def part1(self):
  	# some of the code - less than 65535 characters

  def part2(self):
  	# more of the code

  def part3(self):
  	# the rest of the code

  def __call__(self):
  	self.part1()
  	self.part2()
  	self.part3()
</source>
    </answer>
    </faq>
  </faqsection>
  <faqsection id="g3-ssl">
    <title>SSL</title>
    <faq id="ssl-certificate-choice">
      <question>
      If I have several suitable certificates in my keystore, how does The Grinder chose between them?
      </question>
      <answer>
      <p>The Grinder relies on the JVM's default
      <code>KeyManager</code> implementations. This picks a
      certificate from the store based on SSL negotiation with the
      server. If there are several suitable certificates, the only
      way to control which is used is to <a href="site:g3/ssl/ssl-keymanager">provide your own
      <code>KeyManager</code></a>.</p>
      </answer>
    </faq>
    <faq id="ssl-keystore-passphrase">
      <question>
      <code>setKeyStoreFile</code> has a parameter for the key store password. What about the pass phrase that protects
      the private key in the key store?
      </question>
      <answer>
      <p>The pass phrases for keys must be the same as the key store password. This is a restriction of the default
        <code>KeyManager</code>s. If you don't like this, you can <a href="site:g3/ssl/ssl-keymanager">provide your own
        <code>KeyManager</code></a>.</p>
      </answer>
    </faq>
    <faq id="ssl-specify-certificates">
      <question>
      Shouldn't I need to specify a set of certificates for trusted Certificate Authorities?
      </question>
      <answer>
      <p>No. The Grinder does not validate certficates received from
        the server, so does not need a set of CA certificates.</p>
      </answer>
    </faq>
    <faq id="ssl-global-keystore">
      <question>
      Can I use the properties
        <code>javax.net.ssl.keyStore</code>,
        <code>javax.net.ssl.keyStoreType</code>, and
        <code>javax.net.ssl.keyStorePassword</code> to specify a
        global keystore?
      </question>
      <answer>
      <p>No. The Grinder does not use these properties, primarily
        because the JSSE does not provide a way to access its default
        SSLContext.</p>
      </answer>
    </faq>
  </faqsection>
  <faqsection id="tcpproxy">
    <title>The TCPProxy</title>

    <faq id="what-happened-to-the-tcpsniffer">
      <question>
  What happened to the TCPSniffer?
      </question>

      <answer>
  <p>Starting with The Grinder 3, the TCPSniffer was renamed to
  the TCPProxy to more correctly reflect its nature. The
  TCPProxy has also been significantly enhanced during the
  development of The Grinder 3.</p>
      </answer>
    </faq>

    <faq id="use-the-tcpproxy">
      <question>My server works fine with a
      browser but has errors when I use the HTTP plugin?</question>

      <answer>
  <p>This is probably down to one of the following:</p>

  <ul>
    <li><p>Bugs in your server code. Particularly, those due to
    the way it handles multiple concurrent requests. Don't be
    disheartened, you did good; finding bugs like this is a key
    reason to use The Grinder.</p></li>

    <li>Differences between the HTTP requests that the browser
    uses and those that The Grinder sends.</li>
  </ul>

  <p>The HTTP plugin sends requests that will have minor
  differences between those that a browser send, but which
  rarely affect server behaviour. Its worth knowing how to
  examine the differences with the TCPProxy. First <a
  href="site:g3/getting-started/tcpproxy">set the TCPProxy as a browser
  proxy</a> and record the output to a file. Secondly alter your
  tests so that all requests go via the TCPProxy (the best way
  is to set the test script connections to direct requests via
  the TCPProxy acting an HTTP proxy); again record the output to
  a file. Now grab a coffee and compare.</p>
      </answer>
    </faq>

    <faq id="InvalidKeyException">
      <question>
        I'm getting <code>java.security.InvalidKeyException: Illegal key size
        or default parameters</code>
      </question>

      <answer>
      <p>
       This is due to a mismatch of the SSL configuration of the server
       and that of the JDK you use to run The Grinder; most likely a clash
       between domestic and export strength key lengths. You should probably
       install the <a href="http://java.sun.com/javase/downloads/index.jsp">
       Unlimited Strength Jurisdiction Policy Files</a> for your Java
       version from Sun.
      </p>

      </answer>
     </faq>

    <faq id="tcpproxy-colour-codes">
      <question>
  What are all those funny ^[[31 characters in the TCPProxy
  output?
      </question>
      <answer>
  <p>Did you use the <code>-colour</code> switch? If so, the
  TCPProxy generates escape codes which work on ANSI compliant
  terminals and look very pretty.</p>

  <p>For those of you on Windows platforms, this <em>doesn't
  work</em> with the <code>CMD.EXE</code> window unless you're
  using <a href="ext:cygwin">Cygwin</a>. (Of course, if you're
  using Cygwin you'd use <code>rxvt</code> in preference
  :-)).</p>
      </answer>
    </faq>
    <faq id="tcpproxy-with-ssl">
      <question>
      How do I record a script for a server that uses SSL?
      </question>
      <answer>
      <p>By default, the TCPProxy will use a built-in certificate to handle
      SSL traffic so you don't need to do anything extra, just record a script as normal.</p>
      <p>Should you encounter problems with this, especially when using Internet Explorer to
      connect through the TCPProxy, you will need to provide a server certificate for The Grinder.
      The easiest way to provide a server certificate is to copy the <em>testkeys</em> file
      from the JSSE samples distribution and start the proxy using:</p>
<source>
  java net.grinder.TCPProxy -keyStore testkeys -keyStorePassword passphrase
</source>
      <p>You can specify your own keystore containing relevant client and
      root certificates. Tell the TCPProxy to use the keystore and ssl
      by using the following parameters when invoking the TCPProxy:</p>
<source>
  -keystore <em>(keystore)</em> -keystorepassword <em>(password)</em> -keystoretype <em>(type)</em>
</source>
      <p>Should you encounter further problems with your SSL connection you can
      turn on debug by using the following switch:</p>
<source>
  -Djavax.net.debug=ssl
</source>
      <note>This will generate verbose output.</note>
      </answer>
    </faq>

   </faqsection>

   <faqsection id="console">
    <title>The Console</title>

    <faq id="totals-and-composite-tests">
      <question>
        Why is the test mean time for a page greater than the total mean?
      </question>
      <answer>
        <p>The totals line only includes data from basic tests, i.e. tests that
        do not include other tests. It does not include the data from composite
        tests, i.e. tests that include other tests, such as those those wrapping
        pages in HTTP scripts generated by the TCPProxy. The time taken by these
        page tests is typically quite long since it also includes sleep time and
        can easily exceed the average time for basic tests.</p>

        <p>Composite test lines in the Results tab have a grey backgorund to
        emphasise that they are different.</p>

        <p>This is done so that the totals line is meaningful, useful, and
        understandable. If data from composite tests were included in the totals
        line, some of the values (e.g. average test time) would be meaningless
        since time would be accounted for twice, once by the basic request
        tests, and once by the page test that wrapped the requests.</p>

        <p>Data from composite tests is also not included in the totals line
        in the worker process output log files.</p>
      </answer>
    </faq>
   </faqsection>

  </faqsection>
</faqs>
